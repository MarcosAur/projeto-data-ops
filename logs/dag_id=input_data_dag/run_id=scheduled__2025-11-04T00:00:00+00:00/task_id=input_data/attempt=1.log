[2025-11-05T23:01:50.557+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-05T23:01:50.613+0000] {taskinstance.py:2631} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [queued]>
[2025-11-05T23:01:50.630+0000] {taskinstance.py:2631} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [queued]>
[2025-11-05T23:01:50.631+0000] {taskinstance.py:2884} INFO - Starting attempt 1 of 1
[2025-11-05T23:01:50.646+0000] {taskinstance.py:2907} INFO - Executing <Task(PythonOperator): input_data> on 2025-11-04 00:00:00+00:00
[2025-11-05T23:01:50.658+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=397) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-11-05T23:01:50.659+0000] {standard_task_runner.py:72} INFO - Started process 401 to run task
[2025-11-05T23:01:50.661+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'input_data_dag', 'input_data', 'scheduled__2025-11-04T00:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/input_data_dag.py', '--cfg-path', '/tmp/tmpft5atzo5']
[2025-11-05T23:01:50.662+0000] {standard_task_runner.py:105} INFO - Job 9: Subtask input_data
[2025-11-05T23:01:50.751+0000] {task_command.py:467} INFO - Running <TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [running]> on host 0aab0f5ea6cf
[2025-11-05T23:01:50.939+0000] {taskinstance.py:3157} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='input_data_dag' AIRFLOW_CTX_TASK_ID='input_data' AIRFLOW_CTX_EXECUTION_DATE='2025-11-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-04T00:00:00+00:00'
[2025-11-05T23:01:50.941+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-11-05T23:01:50.942+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-11-05T23:01:50.942+0000] {logging_mixin.py:190} INFO - Current task name:input_data state:running start_date:2025-11-05 23:01:50.614274+00:00
[2025-11-05T23:01:50.943+0000] {logging_mixin.py:190} INFO - Dag name:input_data_dag and current dag run status:running
[2025-11-05T23:01:50.943+0000] {taskinstance.py:740} INFO - ::endgroup::
[2025-11-05T23:01:50.945+0000] {logging_mixin.py:190} INFO - {'conf': <Proxy at 0x7c3eb9324dd0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'conf', <***.configuration.AirflowConfigParser object at 0x7c3ee4aead50>)>, 'dag': <DAG: input_data_dag>, 'dag_run': <DagRun input_data_dag @ 2025-11-04 00:00:00+00:00: scheduled__2025-11-04T00:00:00+00:00, state:running, queued_at: 2025-11-05 23:01:42.101081+00:00. externally triggered: False>, 'data_interval_end': DateTime(2025, 11, 5, 0, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2025, 11, 4, 0, 0, 0, tzinfo=Timezone('UTC')), 'outlet_events': <***.utils.context.OutletEventAccessors object at 0x7c3eb92b5700>, 'ds': '2025-11-04', 'ds_nodash': '20251104', 'execution_date': <Proxy at 0x7c3eb9324e00 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'execution_date', DateTime(2025, 11, 4, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'expanded_ti_count': None, 'inlets': [], 'inlet_events': InletEventsAccessors(_inlets=[], _datasets={}, _dataset_aliases={}, _session=<sqlalchemy.orm.session.Session object at 0x7c3ee46b7950>), 'logical_date': DateTime(2025, 11, 4, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.12/site-packages/***/macros/__init__.py'>, 'map_index_template': None, 'next_ds': <Proxy at 0x7c3eb9324e30 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'next_ds', '2025-11-05')>, 'next_ds_nodash': <Proxy at 0x7c3eb9324e60 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'next_ds_nodash', '20251105')>, 'next_execution_date': <Proxy at 0x7c3eb9324e90 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'next_execution_date', DateTime(2025, 11, 5, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': <Proxy at 0x7c3eb9324ec0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'prev_ds', '2025-11-03')>, 'prev_ds_nodash': <Proxy at 0x7c3eb9324ef0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'prev_ds_nodash', '20251103')>, 'prev_execution_date': <Proxy at 0x7c3eb9324f20 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'prev_execution_date', DateTime(2025, 11, 3, 0, 0, 0, tzinfo=Timezone('UTC')))>, 'prev_execution_date_success': <Proxy at 0x7c3eb9324f50 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'prev_execution_date_success', None)>, 'prev_start_date_success': None, 'prev_end_date_success': None, 'run_id': 'scheduled__2025-11-04T00:00:00+00:00', 'task': <Task(PythonOperator): input_data>, 'task_instance': <TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [running]>, 'task_instance_key_str': 'input_data_dag__input_data__20251104', 'test_mode': False, 'ti': <TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [running]>, 'tomorrow_ds': <Proxy at 0x7c3eb9324f80 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'tomorrow_ds', '2025-11-05')>, 'tomorrow_ds_nodash': <Proxy at 0x7c3eb9324fb0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'tomorrow_ds_nodash', '20251105')>, 'triggering_dataset_events': <Proxy at 0x7c3eb92b4d40 with factory <function _get_template_context.<locals>.get_triggering_events at 0x7c3eb92c8400>>, 'ts': '2025-11-04T00:00:00+00:00', 'ts_nodash': '20251104T000000', 'ts_nodash_with_tz': '20251104T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': <Proxy at 0x7c3eb9324fe0 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'yesterday_ds', '2025-11-03')>, 'yesterday_ds_nodash': <Proxy at 0x7c3eb9325010 with factory functools.partial(<function lazy_mapping_from_context.<locals>._deprecated_proxy_factory at 0x7c3eb92c85e0>, 'yesterday_ds_nodash', '20251103')>, 'templates_dict': None}
[2025-11-05T23:01:50.946+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-11-05T23:01:50.968+0000] {taskinstance.py:349} INFO - ::group::Post task execution logs
[2025-11-05T23:01:50.969+0000] {taskinstance.py:361} INFO - Marking task as SUCCESS. dag_id=input_data_dag, task_id=input_data, run_id=scheduled__2025-11-04T00:00:00+00:00, execution_date=20251104T000000, start_date=20251105T230150, end_date=20251105T230150
[2025-11-05T23:01:51.023+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-11-05T23:01:51.024+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-11-05T23:01:51.025+0000] {logging_mixin.py:190} INFO - Dag name:input_data_dag queued_at:2025-11-05 23:01:42.101081+00:00
[2025-11-05T23:01:51.026+0000] {logging_mixin.py:190} INFO - Task hostname:0aab0f5ea6cf operator:PythonOperator
[2025-11-05T23:01:51.074+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-05T23:01:51.110+0000] {taskinstance.py:3924} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-05T23:01:51.113+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-11-05T23:03:49.391+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-11-05T23:03:49.413+0000] {taskinstance.py:2631} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [queued]>
[2025-11-05T23:03:49.420+0000] {taskinstance.py:2631} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [queued]>
[2025-11-05T23:03:49.420+0000] {taskinstance.py:2884} INFO - Starting attempt 1 of 1
[2025-11-05T23:03:49.429+0000] {taskinstance.py:2907} INFO - Executing <Task(PythonOperator): input_data> on 2025-11-04 00:00:00+00:00
[2025-11-05T23:03:49.436+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=432) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-11-05T23:03:49.437+0000] {standard_task_runner.py:72} INFO - Started process 436 to run task
[2025-11-05T23:03:49.438+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'input_data_dag', 'input_data', 'scheduled__2025-11-04T00:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/input_data_dag.py', '--cfg-path', '/tmp/tmpvjrja_tf']
[2025-11-05T23:03:49.440+0000] {standard_task_runner.py:105} INFO - Job 11: Subtask input_data
[2025-11-05T23:03:49.478+0000] {task_command.py:467} INFO - Running <TaskInstance: input_data_dag.input_data scheduled__2025-11-04T00:00:00+00:00 [running]> on host 0aab0f5ea6cf
[2025-11-05T23:03:49.790+0000] {taskinstance.py:3157} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='input_data_dag' AIRFLOW_CTX_TASK_ID='input_data' AIRFLOW_CTX_EXECUTION_DATE='2025-11-04T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-04T00:00:00+00:00'
[2025-11-05T23:03:49.790+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-11-05T23:03:49.791+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-11-05T23:03:49.791+0000] {logging_mixin.py:190} INFO - Current task name:input_data state:running start_date:2025-11-05 23:03:49.414240+00:00
[2025-11-05T23:03:49.791+0000] {logging_mixin.py:190} INFO - Dag name:input_data_dag and current dag run status:running
[2025-11-05T23:03:49.791+0000] {taskinstance.py:740} INFO - ::endgroup::
[2025-11-05T23:03:49.791+0000] {logging_mixin.py:190} INFO - aaa
[2025-11-05T23:03:49.792+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-11-05T23:03:49.801+0000] {taskinstance.py:349} INFO - ::group::Post task execution logs
[2025-11-05T23:03:49.801+0000] {taskinstance.py:361} INFO - Marking task as SUCCESS. dag_id=input_data_dag, task_id=input_data, run_id=scheduled__2025-11-04T00:00:00+00:00, execution_date=20251104T000000, start_date=20251105T230349, end_date=20251105T230349
[2025-11-05T23:03:49.824+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-11-05T23:03:49.824+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-11-05T23:03:49.824+0000] {logging_mixin.py:190} INFO - Dag name:input_data_dag queued_at:2025-11-05 23:03:46.840412+00:00
[2025-11-05T23:03:49.824+0000] {logging_mixin.py:190} INFO - Task hostname:0aab0f5ea6cf operator:PythonOperator
[2025-11-05T23:03:49.852+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-11-05T23:03:49.870+0000] {taskinstance.py:3924} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-11-05T23:03:49.874+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
